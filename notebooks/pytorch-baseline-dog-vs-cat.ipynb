{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms,datasets\nimport matplotlib.pyplot as plt\nimport torch.optim as optim\nfrom tqdm import tqdm_notebook as tqdm\nimport os\nimport numpy as np\nimport cv2\nimport zipfile\nreprocess_data = True\nfrom PIL import Image\nfrom torchsummary import summary\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ! unzip ../input/dogs-vs-cats/test1.zip \n# ! unzip ../input/dogs-vs-cats/train.zip ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_path = \"./train\"\ntest_path =\"./test1\"\ntrain_files = os.listdir(train_path)\ntest_files = os.listdir(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_files))\nprint(len(test_files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgpath = os.path.join(train_path,train_files[0])\nprint(imgpath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(imgpath,0)\ntype(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgtensor = torch.tensor(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgtensor.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imgtensorresize = transforms.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class Dataset():\n    def __init__(self,filelist,filepath,transform = None):\n        self.filelist = filelist\n        self.filepath = filepath\n        self.transform = transform\n    def __len__(self):\n        return int(len(self.filelist))\n    def __getitem__(self,index):\n        imgpath = os.path.join(self.filepath,self.filelist[index])\n        img = Image.open(imgpath).convert('L')\n        if \"dog\" in imgpath:\n            label = 1\n        else:\n            label = 0 \n        if self.transform is not None:\n            img = self.transform(img)\n        return (img,label)\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformations = transforms.Compose([transforms.Resize((60,60)),transforms.ToTensor()])\ntrain = Dataset(train_files,train_path,transformations)\ntest = Dataset(test_files,test_path,transformations)\ntrain_set,val_set = torch.utils.data.random_split(train,[20000,5000]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train set size :\",train_set.__len__())\nprint(\"val set size :\",val_set.__len__())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.__getitem__(0)[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = torch.utils.data.DataLoader(dataset = train,batch_size = 16,shuffle=True)\ntest_dataset = torch.utils.data.DataLoader(dataset = test,batch_size = 16,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Covnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1,32,5),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n            ) \n            \n        self.conv2 =   nn.Sequential(\n            nn.Conv2d(32,64,5),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n        ) \n        self.conv3 =   nn.Sequential(\n            nn.Conv2d(64,128,5),\n            nn.ReLU(),\n            nn.MaxPool2d(2,2)\n            )\n        self.fc1 = nn.Sequential(\n        nn.Flatten(),\n        nn.Linear(2048,512),\n        nn.ReLU()\n        )\n            \n        self.fc2 = nn.Sequential(\n        nn.Linear(512,2),\n        )\n                \n    def forward(self,x):\n        x= self.conv1(x)\n        x= self.conv2(x)\n        x= self.conv3(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return F.softmax(x,dim = 1) \n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Covnet()\nmodel.cuda()\nsummary(model,(1,60,60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\noptimiser = optim.Adam(model.parameters(),lr=0.001)\nLOSS = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(EPOCHS):\n    model.train()\n    total = 0\n    correct = 0\n    train_loss = 0\n    train_accuracy = 0\n    counter = 0\n    with tqdm(train_dataset, unit=\"batch\") as tepoch:\n        tepoch.set_description(f'Epoch {epoch+1}/{EPOCHS}')\n        for data,label in tepoch:\n            data,label = data.to(device) , label.to(device)\n            optimiser.zero_grad()\n            output = model(data)\n            loss = LOSS(output,label)\n            loss.backward()\n            optimiser.step() \n            train_loss+= loss.item() * data.size(0)\n            _,pred = torch.max(output.data,1)\n            total += label.size(0)\n            correct += (pred == label).sum().item()\n        train_accuracy = correct/total\n#         tepoch.set_postfix(accuracy =train_accuracy,loss = train_loss/len(train_dataset))\n        print(\"=====/train/=====\")\n        print(\"epoch {} train accuracy {}\".format(epoch+1,train_accuracy))\n        print(\"epoch {} train loss {}\".format(epoch+1,train_loss/len(train_dataset)))\n    if epoch %1 == 0:\n        model.eval()\n        total = 0\n        correct = 0\n        val_loss = 0\n        val_accuarcy =0\n        with torch.no_grad():\n            for data,label in test_dataset:\n                data,label = data.to(device),label.to(device)\n                output = model(data)\n                loss = LOSS(output,label)\n                val_loss+= loss.item() * data.size(0)\n                _,pred = torch.max(output.data,1)    \n                total += label.size(0)\n                correct += (pred == label).sum().item()\n            val_accuarcy = correct/total\n            print(\"=====/val/=====\")\n            print(\"epoch {} val accuracy {}\".format(epoch+1,val_accuarcy))\n            print(\"epoch {} val loss {}\".format(epoch+1,val_loss/len(test_dataset)))\n                    \n                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(0%1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}